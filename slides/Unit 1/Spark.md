- Valued added to digital humanities projects:
	- Processing larger data on network
	- Performance:
		- 100 times faster performance for a few applications 
		- Suitable for machine learning algorithms, allows programs to load and query data repeatedly
	- Components of a Spark project
		- Spark core and RDDs
		- Spark SQL
		- Spark streaming
		- MLlib
		- GraphX
- Related papers:
	- "defoe: A Spark-based Toolbox for Analysing Digital Historical Textual Data"
	- Github repository: https://github.com/alan-turing-institute/defoe
- Teaching resource:
	- Spark starter kit (3 hours 18 minutes course)
		- https://www.udemy.com/course/sparkstarterkit/?LSNPUBID=JVFxdTr9V80&ranEAID=JVFxdTr9V80&ranMID=39197&ranSiteID=JVFxdTr9V80-IkFZGhZm.YcTMPFWcST8Sw&utm_medium=udemyads&utm_source=aff-campaign
	- Spark and Python for Big Data with PySpark (10 hours)
		- https://www.udemy.com/course/spark-and-python-for-big-data-with-pyspark/
	- Datacamp - Bigdata with PySpark track (6 courses, 24 hours)
		- https://app.datacamp.com/learn/skill-tracks/big-data-with-pyspark
		- Introduction to PySpark
		- Big data fundamentals with PySpark
		- Cleaning data with PySpark
		- Feature engineering with PySpark
		- Machine learning with PySpark
		- Building recommendation engines with PySpark
- Toolkit comparison:
	- ![[Pasted image 20230915162405.png]]

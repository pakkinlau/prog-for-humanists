{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning\n",
    "\n",
    "This time we also import labels from the newspaper dataset from scikit-learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kinla\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       151\n",
      "           1       0.84      0.88      0.86       202\n",
      "           2       0.89      0.86      0.88       195\n",
      "           3       0.77      0.78      0.78       183\n",
      "           4       0.91      0.91      0.91       205\n",
      "           5       0.92      0.91      0.91       215\n",
      "           6       0.85      0.87      0.86       193\n",
      "           7       0.93      0.95      0.94       196\n",
      "           8       0.98      0.96      0.97       168\n",
      "           9       0.99      0.99      0.99       211\n",
      "          10       0.96      0.99      0.98       198\n",
      "          11       0.98      0.97      0.97       201\n",
      "          12       0.93      0.87      0.90       202\n",
      "          13       0.95      0.95      0.95       194\n",
      "          14       0.96      0.99      0.97       189\n",
      "          15       0.97      0.98      0.97       202\n",
      "          16       0.94      0.96      0.95       188\n",
      "          17       0.98      0.99      0.99       182\n",
      "          18       0.95      0.91      0.93       159\n",
      "          19       0.92      0.85      0.89       136\n",
      "\n",
      "    accuracy                           0.93      3770\n",
      "   macro avg       0.93      0.93      0.93      3770\n",
      "weighted avg       0.93      0.93      0.93      3770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Fetch the dataset\n",
    "newsgroups_data = fetch_20newsgroups(subset='all')\n",
    "X, y = newsgroups_data.data, newsgroups_data.target\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a TfidfVectorizer: Convert a collection of raw documents to a matrix of TF-IDF features\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the LinearSVC model\n",
    "model = LinearSVC()\n",
    "\n",
    "# Fit the model on the train data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Reduce the dimensionality of the data to two dimensions using PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train.toarray())\n",
    "X_test_pca = pca.transform(X_test.toarray())\n",
    "\n",
    "# Train the LinearSVC model on the reduced data\n",
    "model_pca = LinearSVC()\n",
    "model_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "# The function to visualize the decision boundaries\n",
    "def plot_decision_boundary(model, X, y):\n",
    "    # Create a mesh to plot in\n",
    "    h = .02  # step size in the mesh\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # Obtain labels for each point in mesh\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    \n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8)\n",
    "\n",
    "    # Plot also the original points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', linewidth=1, marker='o', s=65)\n",
    "    plt.xlim(X[:, 0].min() - 1, X[:, 0].max() + 1)\n",
    "    plt.ylim(X[:, 1].min() - 1, X[:, 1].max() + 1)\n",
    "\n",
    "# Visualize the model\n",
    "plot_decision_boundary(model_pca, X_test_pca, y_test)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

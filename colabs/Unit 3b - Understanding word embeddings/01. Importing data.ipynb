{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a dataset from existing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kinla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kinla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import nltk\n",
    "\n",
    "# Download the NLTK stop words if you haven't already\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Fetch the 20 Newsgroups dataset\n",
    "newsgroups_data = fetch_20newsgroups(subset='all')\n",
    "\n",
    "# Convert the sklearn bunch object to dictionary\n",
    "newsgroups_dict = {\n",
    "    'data': newsgroups_data.data,\n",
    "    'target': newsgroups_data.target.tolist(),\n",
    "    'target_names': newsgroups_data.target_names\n",
    "}\n",
    "\n",
    "# Save the dataset locally as a JSON file\n",
    "with open('newsgroups_data.json', 'w') as f:\n",
    "    json.dump(newsgroups_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore local dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  target  \\\n",
      "0  From: Mamatha Devineni Ratnam <mr47+@andrew.cm...      10   \n",
      "1  From: mblawson@midway.ecn.uoknor.edu (Matthew ...       3   \n",
      "2  From: hilmi-er@dsv.su.se (Hilmi Eren)\\nSubject...      17   \n",
      "3  From: guyd@austin.ibm.com (Guy Dawson)\\nSubjec...       3   \n",
      "4  From: Alexander Samuel McDiarmid <am2o+@andrew...       4   \n",
      "\n",
      "               target_names  \n",
      "0          rec.sport.hockey  \n",
      "1  comp.sys.ibm.pc.hardware  \n",
      "2     talk.politics.mideast  \n",
      "3  comp.sys.ibm.pc.hardware  \n",
      "4     comp.sys.mac.hardware  \n",
      "rec.sport.hockey            999\n",
      "soc.religion.christian      997\n",
      "rec.motorcycles             996\n",
      "rec.sport.baseball          994\n",
      "sci.crypt                   991\n",
      "rec.autos                   990\n",
      "sci.med                     990\n",
      "comp.windows.x              988\n",
      "sci.space                   987\n",
      "comp.os.ms-windows.misc     985\n",
      "sci.electronics             984\n",
      "comp.sys.ibm.pc.hardware    982\n",
      "misc.forsale                975\n",
      "comp.graphics               973\n",
      "comp.sys.mac.hardware       963\n",
      "talk.politics.mideast       940\n",
      "talk.politics.guns          910\n",
      "alt.atheism                 799\n",
      "talk.politics.misc          775\n",
      "talk.religion.misc          628\n",
      "Name: target_names, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import nltk\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the local JSON file\n",
    "with open('newsgroups_data.json', 'r') as f:\n",
    "    newsgroups_data = json.load(f)\n",
    "\n",
    "# Convert to DataFrame for easier exploration\n",
    "df = pd.DataFrame({\n",
    "    'text': newsgroups_data['data'],\n",
    "    'target': newsgroups_data['target']\n",
    "})\n",
    "df['target_names'] = df['target'].apply(lambda x: newsgroups_data['target_names'][x])\n",
    "\n",
    "# Print the first 5 rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Print the number of each category\n",
    "print(df['target_names'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing from MongoDB altas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
